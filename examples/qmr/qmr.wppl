// var graph = JSON.parse(fs.read('examples/qmr-graph.json'));

var graph = {
  diseases: [{p: .5}, {p: .5}],
  symptoms: [
    {leakProb: 0.001, parents: [{i: 0, p: .9}, {i: 1, p: .1}]},
    {leakProb: 0.001, parents: [{i: 0, p: .9}, {i: 1, p: .1}]}
  ]
};

//console.log(JSON.stringify(graph, null, 2));

var noisyOrProb = function(node, diseases) {
  var pFalse = (1 - node.leakProb) * product(map(function(parent) {
    return diseases[parent.i] ? (1 - parent.p) : 1;
  }, node.parents));
  return 1 - pFalse;
};

// TODO: Thought - it's unclear to me how to evaluate this in a way
// that will distinguish between mean field and a richer guide.
// (Comparing "true" latents with samples from optimized guide doesn't
// see like it will work. If there are two explanations in the true
// posterior, mean-field will sometimes find the right one because of
// mode seeking, and the structure posterior will onyly sometimes find
// it because it might sample from either mode.) As an alternative,
// can we compute the probability the guide assigns to the "true"
// latents by exploiting the sequentiality? Predict, check score of
// "true" val, pretend "true" val was samples, predict, etc.? The
// problem then is, one of the problems with optimizing the ELBo is
// over confidence, which complicates this comparison.


var _model = function() {
  var diseases = map(function(node) {
    return sample(Bernoulli({p: node.p}));
  }, graph.diseases);

  var symptoms = map2(function(node, val) {
    observe(Bernoulli({p: noisyOrProb(node, diseases)}), val);
    //return sample(Bernoulli({p: noisyOrProb(node, diseases)}));
  }, graph.symptoms, [false, true]);

  return {
    diseases: diseases,
    //symptoms: symptoms
  };
};

var iterate = function(n, init, f) {
  if (n === 0) {
    return [];
  } else {
    var val = f(init);
    return [val].concat(iterate(n - 1, val, f));
  }
};

var dict = function(obj) {
  return function(key) {
    return obj[key];
  };
};

var predictMlp = function(state, nonlinearfn) {
  assert.ok(nonlinearfn, 'Non-linear function not given.');
  var i = state.i;
  var ctx = state.ctx;
  var pos = param({name: 'pos'+i});
  var h1 = nonlinearfn(ctx * param({name: 'wp11'}) + param({name: 'wp12'}) * pos + param({name: 'bp1'}));
  var h2 = nonlinearfn(ctx * param({name: 'wp21'}) + param({name: 'wp22'}) * pos + param({name: 'bp2'}));
  return Math.sigmoid(param({name: 'vp1'}) * h1 + param({name: 'vp2'}) * h2 + param({name: 'cp1'}));
};

var sigmoid = function(x) { return Math.sigmoid(x); };
var tanh = function(x) { return Math.tanh(x); };

var predictMlpSigmoid = function(state) { return predictMlp(state, sigmoid); };
var predictMlpTanh = function(state) { return predictMlp(state, tanh); };

var predictDaipp = function(state) {
  return predictMlpTanh(state);
};

var updateDaipp = function(state, v) {
  var i = state.i;
  var pos = param({name: 'update_pos' + i});
  var ctx = state.ctx;

  return Math.tanh(
    pos * param({name: 'update_w1'}) +
    v * param({name: 'update_w2'}) +
    ctx * param({name: 'update_w3'}) +
    param({name: 'update_b'}));
};

var daipp = dict({
  predict: predictDaipp,
  update: updateDaipp,
  embed: function(val) {
    return val ? 1 : 0;
  }
});

var mf = dict({
  predict: function(state) {
    var i = state.i;
    return Math.sigmoid(param({name: 'p' + i}));
  },
  update: function(state, v) {
    return state.ctx;
  },
  embed: function(val) {
    return val ? 1 : 0;
  }
});

var guide = mf;
//var guide = daipp;

var model = function() {
  var steps = iterate(
    graph.diseases.length,
    {i: 0, ctx: 0}, // Initial state.
    function(state) {
      var predict = guide('predict'), update = guide('update'), embed = guide('embed');

      var p = predict(state);

      var val = sample(Bernoulli({p: graph.diseases[state.i].p}), {
        guide: Bernoulli({p: p})
      });

      var ctx = update(state, embed(val));

      return {
        i: state.i + 1,
        ctx: ctx,
        val: val
        // p: p
      };
    });

  var diseases = _.pluck(steps, 'val');
  var symptoms = map2(function(node, val) {
    observe(Bernoulli({p: noisyOrProb(node, diseases)}), val);
  }, graph.symptoms, [false, true]);

  return {diseases: diseases};
};


var q = Infer({
  method: 'optimize',
  samples: 10000,
  steps: 10000,
  optMethod: {adam: {stepSize: 0.01}}
}, function() {
  return model().diseases;
});

var p = Enumerate(function() {
  return model().diseases;
});

display('p');
display(p.print());
display('q');
display(q.print());

kl(q,p);
